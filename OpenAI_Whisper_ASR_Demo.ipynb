{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zsj1zsj/OpenAI_Whisper_ASR_Demo/blob/main/OpenAI_Whisper_ASR_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Web App Demonstrating OpenAI's Whisper Speech Recognition Model\n",
        "\n",
        "This is a Colab notebook that allows you to record or upload audio files to [OpenAI's free Whisper speech recognition model](https://openai.com/blog/whisper/). This was based on [an original notebook by @amrrs](https://github.com/amrrs/openai-whisper-webapp), with added documentation and test files by [Pete Warden](https://twitter.com/petewarden).\n",
        "\n",
        "To use it, choose `Runtime->Run All` from the Colab menu. If you're viewing this notebook on GitHub, follow [this link](https://colab.research.google.com/github/petewarden/openai-whisper-webapp/blob/main/OpenAI_Whisper_ASR_Demo.ipynb) to open it in Colab first. After about a minute or so, you should see a button at the bottom of the page with a `Record from microphone` link. Click this, you'll be asked to give permission to access your mic, and then speak for up to 30 seconds. Once you're done, press `Stop recording`, and a transcript of the first 30 seconds of your speech should soon appear in the box to the right of the recording button. To transcribe more speech, click `Clear' in the left box and start over.\n",
        "\n",
        "You can also upload your own audio samples using the folder icon on the left of this page. That gives you access to a file system you can upload to by dragging files into it. You can see examples of how to run the transcription in a couple of the cells below."
      ],
      "metadata": {
        "id": "Lbja1jB3vDOT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install the Whisper Code"
      ],
      "metadata": {
        "id": "kosakhNmxb7A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZsJUxc0aRsAf",
        "outputId": "0e36b1e3-9289-4de7-ddb1-019041a39a2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 5.3 MB 16.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 55.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 163 kB 60.7 MB/s \n",
            "\u001b[?25h  Building wheel for whisper (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "! pip install git+https://github.com/openai/whisper.git -q"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the ML Model"
      ],
      "metadata": {
        "id": "AtAvuKSJxhNw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "model = whisper.load_model(\"medium\")\n"
      ],
      "metadata": {
        "id": "Kr5faKybKi4p",
        "outputId": "92a60272-5110-4f8a-f08f-fbe1f38625f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 77%|████████████████████████████▎        | 2.20G/2.87G [00:43<00:12, 57.3MiB/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check we have a GPU\n",
        "\n",
        "You should see the output `device(type='cuda', index=0)` below. If you don't, you may be on a CPU-only Colab instance which will run more slowly. Go to `Runtime->Change Runtime Type` to fix this."
      ],
      "metadata": {
        "id": "e200RNNlxn5j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.device"
      ],
      "metadata": {
        "id": "u_6_s2iHboR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipython-autotime\n",
        "%load_ext autotime"
      ],
      "metadata": {
        "id": "Zivot1D_WuQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ming\n",
        "!mkdir srt\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "from datetime import datetime\n",
        "import glob\n",
        "\n",
        "\n",
        "\n",
        "def sortfilebysize(dir_name):\n",
        "  list_of_files = filter( os.path.isfile,\n",
        "                        glob.glob(dir_name + '*') )\n",
        "  list_of_files = sorted( list_of_files,\n",
        "                        key =  lambda x: os.stat(x).st_size)\n",
        "  return list_of_files\n",
        "\n",
        "sortfilebysize('/content/ming/')"
      ],
      "metadata": {
        "id": "sCvObwGUqAFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install tqdm\n",
        "import tqdm\n",
        "import glob\n",
        "from datetime import datetime, timezone, timedelta\n",
        "\n",
        "tz = timezone(timedelta(hours=+8))\n",
        "now = datetime.now(tz)\n",
        "nowstr = now.strftime(\"%H:%M\")\n",
        "\n",
        "# files = sorted(glob.glob('/content/ming/*'))\n",
        "files = sortfilebysize('/content/ming/')\n",
        "\n",
        "pbar = tqdm.tqdm(files)\n",
        "for file in pbar:\n",
        "    now = datetime.now(tz)\n",
        "    nowstr = now.strftime(\"%H:%M\")\n",
        "    pbar.set_description(nowstr+' '+file[14:-8])\n",
        "\n",
        "    test_txt = model.transcribe(file)\n",
        "\n",
        "    srtPath = '/content/srt/'+ file[14:] + '.txt'\n",
        "    with open(srtPath, mode = 'w', encoding = 'utf-8') as f: \n",
        "      f.write(test_txt['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhUSBQnfDzAL",
        "outputId": "e0a2527e-4e6e-4e59-ad88-30ab17b98600"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "20:44 41-【迷離公路】ep157 韓國三豐百貨靈異傳聞 第二節 (:  70%|███████   | 7/10 [25:15<11:14, 224.99s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/file.zip /content/srt/"
      ],
      "metadata": {
        "id": "cuFfFU0xYAMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/file.zip\")"
      ],
      "metadata": {
        "id": "F6bEphwbYbJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import glob\n",
        "\n",
        "# files = glob.glob('/content/ming/*')\n",
        "# print(files)\n",
        "# for f in files:\n",
        "#     os.remove(f)\n",
        "\n",
        "# files = glob.glob('/content/srt/*')\n",
        "# for f in files:\n",
        "#     os.remove(f)\n",
        "\n",
        "# os.remove('/content/file.zip')"
      ],
      "metadata": {
        "id": "jUQUz75eZ4Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !cp ./sample_data/anscombe.json ./drive/MyDrive/temp/"
      ],
      "metadata": {
        "id": "EwLX8O7MGOfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "KA6WoCJNGPXK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}